       	       	     +-------------------------+
		     |		CS 140	       |
		     | PROJECT 4: FILE SYSTEMS |
		     |	   DESIGN DOCUMENT     |
		     +-------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Woosun Song wireless@kaist.ac.kr

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

I have implemented the dentry cache.
Dentry cache can be disabled by commenting out `#define DENTRY_CACHE 1` in dentry_cache.c, line 9.
Also, the dentry cache benchmark can be ran by the script `run-benchmark.sh` in filesys directory.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

		     INDEXED AND EXTENSIBLE FILES
		     ============================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

I did not implement any new structures for extensible files.

>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.

The maximum size of a file supported by my inode is 128 * 128 * 512 bytes.
The largest inode is a two-level indexed inode, and each level can have up to 512/4 subentries.
Each 2nd level pointer can accomondate up to 128 * 512 bytes. Furthermore, each 1st level pointer contains 128 2nd level pointers. In total, there are 512 * 128 * 128 bytes available.

---- SYNCHRONIZATION ----

>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.

For each inode, there is a lock. To extend an inode, that lock must be acquired. Since the only path in PintOS that can extend a file is by writing to it, there cannot be two simultaneous file extensions due to the per inode lock.

>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.

This can be avoided by considering 'reads beyond file size' equivalent to 'writes beyond file size'. In other words, if a read operation attempts to read beyond a file, it acquires the per-inode lock.

>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.

My synchornization design provides fairness because there is no locking for writes(that do not extend files) and reads(that do not read beyond the file). Therefore, all threads can simulatenously operate as long as they do not extend or read beyond files.

---- RATIONALE ----

>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?

My inode structure is not a multilevel index. Instead, it only has one type of level index. I chose this implementation to reduce the complexity of the inode structure. A disadvantage of this implementation is that it is inferior than multilevel indexing in terms of space utilization.

			    SUBDIRECTORIES
			    ==============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In `struct process_info`, I've added the `cwd` field, which is of type `struct dir *`.

---- ALGORITHMS ----

>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?

Traversals of absolute and relative paths differ in the initial directory selected for iteration. For absolute paths, the initial directory is the root directory. For relative paths, the initial directory is the current working directory.

---- SYNCHRONIZATION ----

>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.

All directory accesses are synchronized via a global lock, `dir_lock`. This effectively prevents all simultaneous accesses to a single directory.

>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?

It does not allow a directory to be removed if it is open by a process or a cwd. This is implemented by prohibiting removal of directories whose inode's reference count is larger than 2. (The threshold is 2 because the victim directory is opened once by the code attempting the removal)

---- RATIONALE ----

>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.

I chose to represent the current working directory to `dir *` for the two reasons. First, the time for finding that directory can be reduced greatly. Second, it eliminates the complexity when dealing with races, because as long as the directory structure 'grabs' the inode it has no chance of being removed from memory.

			     BUFFER CACHE
			     ============

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

I have implemented the following structure for a buffer cache entry.

```
struct bcache_entry {
	struct lock lock;
	bool in_use;
	int64_t last_use;
	block_sector_t sector;
	uint8_t data[BLOCK_SECTOR_SIZE];
};
```

---- ALGORITHMS ----

>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.

My cache replacment polciy is LRU. It is implemented by placing a timestamp field for each buffer cache. Whenever reads or writes to the buffer cache occurs, the timestamp is updated to the current timer ticks. The victim of eviction becomes the cache entry with the lowest timestamp value.

>> C3: Describe your implementation of write-behind.
Write-behind is implemented by 'proxy'ing writes to disk via buffer cache. In `inode.c`, there is code that needs to write to disk. All of these operations are switched to operations writing to the buffer cache.

>> C4: Describe your implementation of read-ahead.
Read ahead is triggered when the amount of bytes to read are larger than the block size. A new thread is created upon read-ahead triggering. The thread receives the next sector via a condition variable. The thread reads the corresponding block sector into the buffer cache.

However, I disabled my implementation of read-ahead because it had a negative effect on performance. I speculate the reason for the performance drop is because of the synchronziation primitives between the main threads and the read-ahead threads spends too many cycles.

---- SYNCHRONIZATION ----

>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?

All accesses to the buffer cache are synchronized using a per-entry lock. Before eviction, the per-entry lock is acquired. Therefore, it is impossible to read from a cache entry while eviction is taking place.

>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?

This is already explained in C5. Eviction can only occur under the context of a lock being acquired. Also, before reading from the buffer cache the thread must acquire that lock. Therefore, a thread cannot read from a buffer cache entry being evicted.

---- RATIONALE ----

>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.

A workload likely to benefit from buffer caching is a workload that operates on the same file, same offset multiple times within a short time period. One example is when two processes are using a small file for IPC.

A workload likely to benefit from read-ahead is long sequential reads. Due to the background thread that performs read-ahead, sequential reads can have at most 2X performance improvement. 

A workload likely to benefit from write-behind is writes to the same location. If writes to the same location are done within a short time period, all of those writes can be synchronized to the disk at once, instead of being written multiple times.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?

>> Any other comments?
